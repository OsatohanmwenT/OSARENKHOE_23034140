{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f34a759",
   "metadata": {},
   "source": [
    "# Emotion Detection Model Training\n",
    "\n",
    "This notebook demonstrates how to train an emotion detection model using scikit-learn.\n",
    "We'll use the FER2013 dataset or a similar emotion dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086010e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import joblib\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Set style\n",
    "sns.set_style('darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd6757b",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Dataset\n",
    "\n",
    "For demonstration purposes, we'll create a simple dataset.\n",
    "In production, you would load the FER2013 dataset or similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2b7f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion labels\n",
    "EMOTIONS = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "# For demo: Create synthetic data\n",
    "# In practice, load from FER2013 CSV or image dataset\n",
    "def create_demo_dataset(n_samples=1000, img_size=48):\n",
    "    \"\"\"\n",
    "    Create a demo dataset for testing\n",
    "    Replace this with actual dataset loading\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate random images and labels\n",
    "    X = np.random.rand(n_samples, img_size * img_size)\n",
    "    y = np.random.randint(0, len(EMOTIONS), n_samples)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Load data\n",
    "print(\"Loading dataset...\")\n",
    "X, y = create_demo_dataset(n_samples=5000)\n",
    "print(f\"Dataset shape: X={X.shape}, y={y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792a5a2b",
   "metadata": {},
   "source": [
    "## 2. Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926f34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "\n",
    "# Check class distribution\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "for emotion_idx, count in zip(unique, counts):\n",
    "    print(f\"{EMOTIONS[emotion_idx]}: {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eef205e",
   "metadata": {},
   "source": [
    "## 3. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c517b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features scaled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42497244",
   "metadata": {},
   "source": [
    "## 4. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b34e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest Classifier\n",
    "print(\"Training Random Forest model...\")\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9dc8a1",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb07f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nTest Accuracy: {accuracy * 100:.2f}%\\n\")\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=EMOTIONS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dc33a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=EMOTIONS, yticklabels=EMOTIONS)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddf8d96",
   "metadata": {},
   "source": [
    "## 6. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847acc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "feature_importance = model.feature_importances_\n",
    "\n",
    "# Plot top 20 features\n",
    "top_features = np.argsort(feature_importance)[-20:]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(20), feature_importance[top_features])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature Index')\n",
    "plt.title('Top 20 Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8823053",
   "metadata": {},
   "source": [
    "## 7. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48887c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model_path = '../models/emotion_model.pkl'\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"✓ Model saved to {model_path}\")\n",
    "\n",
    "# Also save the scaler\n",
    "scaler_path = '../models/scaler.pkl'\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"✓ Scaler saved to {scaler_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ea70c6",
   "metadata": {},
   "source": [
    "## 8. Test Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d591ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and test the saved model\n",
    "loaded_model = joblib.load(model_path)\n",
    "loaded_scaler = joblib.load(scaler_path)\n",
    "\n",
    "# Test prediction\n",
    "test_sample = X_test_scaled[0:1]\n",
    "prediction = loaded_model.predict(test_sample)\n",
    "probabilities = loaded_model.predict_proba(test_sample)\n",
    "\n",
    "print(f\"Predicted emotion: {EMOTIONS[prediction[0]]}\")\n",
    "print(f\"\\nProbabilities:\")\n",
    "for emotion, prob in zip(EMOTIONS, probabilities[0]):\n",
    "    print(f\"{emotion}: {prob*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2881cb04",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Use Real Dataset**: Replace demo data with FER2013 or similar\n",
    "2. **Try Deep Learning**: Use CNN with TensorFlow/Keras for better accuracy\n",
    "3. **Hyperparameter Tuning**: Use GridSearchCV or RandomizedSearchCV\n",
    "4. **Data Augmentation**: Increase dataset size with transformations\n",
    "5. **Ensemble Methods**: Combine multiple models for better performance"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
